# LibLearn
Por Davi Augusto Nascimento Filippini, Jairo Medeiros Mendes e Kauan Pollicarpo Pereira


Projeto TCC - Inclusão e Tradução em Libras com Inteligência Artificial

Descrição Geral

Este projeto de TCC é inspirado no Hand Talk e busca promover a inclusão de pessoas surdas ao criar uma ferramenta que traduz gestos da Língua Brasileira de Sinais (Libras) para linguagem textual ou verbal. A solução utiliza inteligência artificial e aprendizado de máquina para realizar o reconhecimento de sinais em tempo real, ajudando a facilitar a comunicação e proporcionar maior autonomia para as pessoas surdas.

Objetivos do Projeto

Desenvolver uma ferramenta que interprete sinais em Libras de forma eficiente e precisa.

Utilizar tecnologias acessíveis para promover a inclusão social e a comunicação entre surdos e ouvintes.

Integrar aprendizado de máquina para aprimorar o reconhecimento e a tradução em tempo real.

Oferecer uma experiência intuitiva para os usuários.

Tecnologias Utilizadas

Linguagens de programação: Python.

Frameworks e bibliotecas:

TensorFlow / Keras para treinamento de modelos.

OpenCV para captura de imagens e processamento de vídeo.

Teachable Machine para prototipação de modelos.

Hardware:

Câmeras integradas (ex.: webcam ou câmeras de dispositivos móveis) para captura de movimentos.

Estrutura do Projeto

Coleta de Dados:

Foram capturadas 200 amostras de gestos da mão direita e 200 da mão esquerda para cada sinal em Libras.

Os dados coletados incluem imagens e pontos-chave dos movimentos.

Treinamento do Modelo:

Os dados coletados foram utilizados para treinar um modelo de aprendizado de máquina.

A performance do modelo foi avaliada com métricas como acurácia e F1-Score.

Implementação:

Integração do modelo treinado em uma interface capaz de traduzir os sinais capturados pela câmera para texto ou voz.

Testes:

Testes realizados com usuários reais para validação da precisão do reconhecimento dos sinais.

Funcionalidades Principais

Captura de sinais em Libras através de uma câmera.

Tradução em tempo real dos sinais capturados para texto ou voz.

Interface intuitiva e inclusiva para facilitar o uso por diferentes tipos de usuários.

Resultados Esperados

Alta taxa de acurácia no reconhecimento de sinais em Libras.

Experiência de usuário fluida, com respostas rápidas e precisas.

Promoção da inclusão social através de uma ferramenta acessível e fácil de usar.

Contribuições

Inclusão social: Proporciona autonomia e facilita a comunicação para a comunidade surda.

Avanços tecnológicos: Integração de IA com tecnologias acessíveis para resolução de problemas sociais.

Futuras Implementações

Melhorar o treinamento do modelo com mais amostras de sinais em Libras.

Expandir a solução para outras línguas de sinais.

Adicionar suporte para dispositivos móveis.

Implementar um sistema de feedback para que os usuários possam corrigir eventuais erros de interpretação.

Agradecimentos

Este projeto é dedicado a todas as pessoas que contribuíram para a minha formação como cientista da computação durante os anos letivos de 2021 a 2024, nas FIB - Faculdades Integradas de Bauru. Primeiramente, quero agradecer aos professores por todo o apoio e motivação nesses anos. Agradeço também aos meus amigos que estiveram ao meu lado nesta jornada (os créditos estão nos arquivos). Sem vocês, este projeto não seria possível. Obrigado a todos os meus amigos. Que Deus abençoe suas jornadas, onde quer que vocês estejam. Espero que todos encontrem tudo aquilo que procuram. A gente se encontra algum dia, se Deus quiser. Um forte abraço.

Att: Kauan Pollicarpo Pereira

Autores: [Dani Augusto Nascimento Filippini, Jairo Medeiros Mendes e Kauan Pollicarpo Pereira  ]Orientador: [Ronaldo Dametto]Instituição: [FIB - Faculdades Integradas de Bauru]Data: [2024]

Nota: Este README descreve de forma geral o projeto e pode ser adaptado conforme o desenvolvimento ou novas especificações. Caso você tenha interesse no tema ou sugestões de melhorias, sinta-se à vontade para colaborar!

